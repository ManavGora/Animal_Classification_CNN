{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-03T18:34:17.794197Z",
     "iopub.status.busy": "2023-07-03T18:34:17.793443Z",
     "iopub.status.idle": "2023-07-03T18:34:17.80513Z",
     "shell.execute_reply": "2023-07-03T18:34:17.803931Z",
     "shell.execute_reply.started": "2023-07-03T18:34:17.794161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, f1_score , confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout , BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers,models,Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T18:34:20.811625Z",
     "iopub.status.busy": "2023-07-03T18:34:20.811151Z",
     "iopub.status.idle": "2023-07-03T18:34:23.729789Z",
     "shell.execute_reply": "2023-07-03T18:34:23.728835Z",
     "shell.execute_reply.started": "2023-07-03T18:34:20.811583Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/animal-image-dataset-90-different-animals/animals/animals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: [] , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: [] }\n\u001b[0;32m----> 6\u001b[0m category \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m category:\n\u001b[1;32m      8\u001b[0m     folderpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path , folder)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/animal-image-dataset-90-different-animals/animals/animals'"
     ]
    }
   ],
   "source": [
    "path = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\"\n",
    "\n",
    "\n",
    "data = {\"imgpath\": [] , \"labels\": [] }\n",
    "\n",
    "category = os.listdir(path)\n",
    "for folder in category:\n",
    "    folderpath = os.path.join(path , folder)\n",
    "    filelist = os.listdir(folderpath)\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(folderpath, file)\n",
    "        data[\"imgpath\"].append(fpath)\n",
    "        data[\"labels\"].append(folder)\n",
    "      \n",
    "\n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "#Convert labels to numbers\n",
    "lb = LabelEncoder()\n",
    "df['encoded_labels'] = lb.fit_transform(df['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Dataset into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T18:34:27.42921Z",
     "iopub.status.busy": "2023-07-03T18:34:27.428714Z",
     "iopub.status.idle": "2023-07-03T18:34:27.454543Z",
     "shell.execute_reply": "2023-07-03T18:34:27.453452Z",
     "shell.execute_reply.started": "2023-07-03T18:34:27.429169Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, Temp_df = train_test_split(df,  train_size= 0.70 , shuffle=True, random_state=124)\n",
    "valid_df , test_df = train_test_split(Temp_df ,  train_size= 0.70 , shuffle=True, random_state=124)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"----------Train-------------\")\n",
    "print(train_df[[\"imgpath\", \"labels\"]].head(5))\n",
    "print(train_df.shape)\n",
    "print(\"--------Validation----------\")\n",
    "print(valid_df[[\"imgpath\", \"labels\"]].head(5))\n",
    "print(valid_df.shape)\n",
    "print(\"----------Test--------------\")\n",
    "print(test_df[[\"imgpath\", \"labels\"]].head(5))\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T18:34:32.15752Z",
     "iopub.status.busy": "2023-07-03T18:34:32.156628Z",
     "iopub.status.idle": "2023-07-03T18:34:36.281244Z",
     "shell.execute_reply": "2023-07-03T18:34:36.280006Z",
     "shell.execute_reply.started": "2023-07-03T18:34:32.157489Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "for i, row in test_df.sample(n=16).reset_index().iterrows():\n",
    "    plt.subplot(4,4,i+1)\n",
    "    image_path = row['imgpath']\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(row[\"labels\"])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:39:38.314202Z",
     "iopub.status.busy": "2023-07-03T19:39:38.313609Z",
     "iopub.status.idle": "2023-07-03T19:39:45.034662Z",
     "shell.execute_reply": "2023-07-03T19:39:45.033729Z",
     "shell.execute_reply.started": "2023-07-03T19:39:38.314164Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "BATCH_SIZE = 15\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "generator = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "    # there could be image augmentation here\n",
    ")\n",
    "\n",
    "# Split the data into three categories.\n",
    "train_images = generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='imgpath',\n",
    "    y_col='labels',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_images = generator.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col='imgpath',\n",
    "    y_col='labels',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_images = generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='imgpath',\n",
    "    y_col='labels',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:33:43.065425Z",
     "iopub.status.busy": "2023-07-03T20:33:43.065067Z",
     "iopub.status.idle": "2023-07-03T20:33:46.68777Z",
     "shell.execute_reply": "2023-07-03T20:33:46.686746Z",
     "shell.execute_reply.started": "2023-07-03T20:33:43.065395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.EfficientNetB3(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False, # we don`t need a pre-trained top layer (output layer)\n",
    "    weights='imagenet',\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "# Freezing the layers of a pretrained neural network\n",
    "for i, layer in enumerate(pretrained_model.layers):\n",
    "    pretrained_model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:34:13.870413Z",
     "iopub.status.busy": "2023-07-03T20:34:13.869962Z",
     "iopub.status.idle": "2023-07-03T20:34:15.735913Z",
     "shell.execute_reply": "2023-07-03T20:34:15.735123Z",
     "shell.execute_reply.started": "2023-07-03T20:34:13.870379Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(set(train_images.classes))\n",
    "\n",
    "\n",
    "# Data Augmentation Step\n",
    "augment = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.15),\n",
    "  layers.experimental.preprocessing.RandomZoom(0.15),\n",
    "  layers.experimental.preprocessing.RandomContrast(0.15),\n",
    "], name='AugmentationLayer')\n",
    "\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape = (224,224,3), name='inputLayer')\n",
    "x = augment(inputs)\n",
    "pretrain_out = pretrained_model(x, training = False)\n",
    "x = layers.Dense(256)(pretrain_out)\n",
    "x = layers.Activation(activation=\"relu\")(x) \n",
    "x = BatchNormalization()(x)\n",
    "x = layers.Dropout(0.45)(x)\n",
    "x = layers.Dense(num_classes)(x)\n",
    "outputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) # mixed_precision need separated Dense and Activation layers\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# model.load_weights('./checkpoints/my_checkpoint')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training : Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:34:33.117117Z",
     "iopub.status.busy": "2023-07-03T20:34:33.116717Z",
     "iopub.status.idle": "2023-07-03T20:35:26.550101Z",
     "shell.execute_reply": "2023-07-03T20:35:26.547517Z",
     "shell.execute_reply.started": "2023-07-03T20:34:33.117086Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 3,\n",
    "                               restore_best_weights = True), # if val loss decreases for 10 epochs in a row, stop training,\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') \n",
    "    ]\n",
    ")\n",
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:16:31.366893Z",
     "iopub.status.busy": "2023-07-03T20:16:31.366542Z",
     "iopub.status.idle": "2023-07-03T20:16:32.039651Z",
     "shell.execute_reply": "2023-07-03T20:16:32.038773Z",
     "shell.execute_reply.started": "2023-07-03T20:16:31.366864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_acc = history.history['accuracy']\n",
    "tr_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "index_acc = np.argmax(val_acc)\n",
    "acc_highest = val_acc[index_acc]\n",
    "Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training : Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:16:41.00936Z",
     "iopub.status.busy": "2023-07-03T20:16:41.008918Z",
     "iopub.status.idle": "2023-07-03T20:33:29.993889Z",
     "shell.execute_reply": "2023-07-03T20:33:29.991777Z",
     "shell.execute_reply.started": "2023-07-03T20:16:41.009322Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model.trainable = True\n",
    "for layer in pretrained_model.layers:\n",
    "    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n",
    "        layer.trainable = False\n",
    "        \n",
    "# let`s see first 10 layers\n",
    "for l in pretrained_model.layers[:10]:\n",
    "    print(l.name, l.trainable)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# model.load_weights('./checkpoints/my_checkpoint')\n",
    "print(model.summary())\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=15,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 3,\n",
    "                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') \n",
    "    ]\n",
    ")\n",
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:59:48.778744Z",
     "iopub.status.busy": "2023-07-03T19:59:48.778075Z",
     "iopub.status.idle": "2023-07-03T19:59:49.41778Z",
     "shell.execute_reply": "2023-07-03T19:59:49.416842Z",
     "shell.execute_reply.started": "2023-07-03T19:59:48.778712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_acc = history.history['accuracy']\n",
    "tr_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "index_acc = np.argmax(val_acc)\n",
    "acc_highest = val_acc[index_acc]\n",
    "Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:00:04.830056Z",
     "iopub.status.busy": "2023-07-03T20:00:04.829469Z",
     "iopub.status.idle": "2023-07-03T20:00:12.575816Z",
     "shell.execute_reply": "2023-07-03T20:00:12.574655Z",
     "shell.execute_reply.started": "2023-07-03T20:00:04.830017Z"
    }
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score / Recall / Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:00:17.779906Z",
     "iopub.status.busy": "2023-07-03T20:00:17.779226Z",
     "iopub.status.idle": "2023-07-03T20:00:24.86971Z",
     "shell.execute_reply": "2023-07-03T20:00:24.868825Z",
     "shell.execute_reply.started": "2023-07-03T20:00:17.779873Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = test_images.classes\n",
    "y_pred = np.argmax(model.predict(test_images), axis = 1)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(\"F1 Score:\", f1)\n",
    "print(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:00:42.475833Z",
     "iopub.status.busy": "2023-07-03T20:00:42.475467Z",
     "iopub.status.idle": "2023-07-03T20:00:45.886015Z",
     "shell.execute_reply": "2023-07-03T20:00:45.884924Z",
     "shell.execute_reply.started": "2023-07-03T20:00:42.475803Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\n",
    "Predictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n",
    "                            \"Test Labels\" : test_images.labels, \n",
    "                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n",
    "                            \"Prediction Labels\" : y_pred,\n",
    "                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n",
    "                            \"Path\": test_images.filenames,\n",
    "                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n",
    "                           })\n",
    "Predictions.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the most confident errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:00:56.034711Z",
     "iopub.status.busy": "2023-07-03T20:00:56.034348Z",
     "iopub.status.idle": "2023-07-03T20:01:02.232095Z",
     "shell.execute_reply": "2023-07-03T20:01:02.229312Z",
     "shell.execute_reply.started": "2023-07-03T20:00:56.034681Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n",
    "    plt.subplot(5,4,i+1)\n",
    "    image_path = row['Path']\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrics and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T20:04:54.579863Z",
     "iopub.status.busy": "2023-07-03T20:04:54.579397Z",
     "iopub.status.idle": "2023-07-03T20:05:14.749193Z",
     "shell.execute_reply": "2023-07-03T20:05:14.748001Z",
     "shell.execute_reply.started": "2023-07-03T20:04:54.579824Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_images)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "g_dict = test_images.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_images.classes, y_pred)\n",
    "\n",
    "plt.figure(figsize= (30, 30))\n",
    "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation= 45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1554380,
     "sourceId": 3952946,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30512,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
